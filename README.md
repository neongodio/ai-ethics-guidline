# AI Ethics Guidline


### Human agency and oversight:
AI systems should augment, not replace, human decision-making. They should not be used to automate decisions that significantly impact human life or well-being without human oversight. AI should be designed to support human decision-making, not to make decisions on its own.

### Transparency and accountability:
AI systems should be transparent in their operation and decision-making processes. Users should understand how AI systems work and how they make decisions. Mechanisms should be in place to hold those responsible for developing and using AI systems accountable for their actions.

### Fairness, non-discrimination, inclusion, and diversity:
AI should be designed to avoid bias, ensure fairness, and promote diversity and inclusion. It should respect the rights and dignity of all users, irrespective of their race, gender, age, or other characteristics. It should not be used to discriminate against individuals or groups based on protected characteristics.

### Privacy and data protection:
AI should respect privacy rights and maintain data confidentiality. AI systems should be designed with privacy in mind, not collecting or using personal data without individual consent. They should also be designed to minimize the risk of data breaches.

### Safety, security, and responsibility:
AI must be developed and used responsibly with safety and security as priorities. AI systems should be tested for safety and security before deployment. Measures should be in place to mitigate risks of harm, such as plans for dealing with system failures.

### Accountability for unintended consequences:
Developers and users of AI systems should be aware of the potential for unintended consequences and take steps to mitigate these risks. There should be mechanisms in place to hold those responsible for developing and using AI systems accountable for their actions, including the potential unintended consequences.

### Sustainability:
AI systems should be developed and used sustainably. They should be designed to be energy-efficient and should not consume excessive amounts of resources or promote harmful or unsustainable practices.

### Continuous monitoring, learning, and regulatory compliance:
AI ethics require continuous monitoring, reassessment, and learning. Organizations must regularly update their ethical guidelines based on the latest research, societal changes, and legal regulations. AI development and usage must comply with all applicable laws and regulations.

### Public and stakeholder engagement:
There should be open dialogues with the public and other stakeholders about AI's ethical implications. The public should have a say in how AI systems are developed and used, and their concerns should be considered.

### Ethical impact assessment:
AI systems should be subject to ethical impact assessments to identify and mitigate potential ethical risks. These risks should be evaluated and mitigated before the system is deployed.


## References

* Asilomar AI Principles (2016)
* Montreal Declaration for Responsible AI (2018)
* Ethics Guidelines for Trustworthy AI (2019)
* IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems (2019)
* AI Principles for People (2020)
* BCG AI Ethics Guidelines (2022)
* The Ethics Guidelines for Trustworthy AI, developed by the European Commission's High-Level Expert Group on Artificial Intelligence (AI HLEG).
* The AI Principles for Transparency and Accountability, developed by the Partnership on AI.
* The Ten Principles for the AI We Need, developed by the Berkman Klein Center for Internet & Society at Harvard University.
* The Montreal Declaration for Responsible AI, developed by the Montreal Institute for Learning Algorithms.
* The Ethics of AI in the Age of Surveillance Capitalism (The Atlantic, June 13, 2023)
* How to Build an Ethical AI (MIT Technology Review, June 8, 2023)
* The 10 Biggest Ethical Challenges of AI (Forbes, May 24, 2023)
* AI Ethics: A Primer (The Brookings Institution, May 17, 2023)
* The Future of AI Ethics (Nature, May 10, 2023)
* The AI Ethics Toolkit (Ethics of AI)
* The AI Ethics Framework (Stanford University)
* The AI Ethics Guidebook (The Future Society)
* Ethics Guidelines for Trustworthy AI (European Union, 2019)
* Ten Core Principles for the Ethics of Artificial Intelligence (UNESCO, 2019)
* Ethical Principles for Artificial Intelligence in Defense (U.S. Department of Defense, 2020)
* AI Principles for Responsible Development (Google AI, 2020)
* AI Principles for Social Impact (Microsoft, 2020)
* AI Principles for Good (Amazon Web Services, 2021)
* AI Principles for Inclusive Growth (World Economic Forum, 2021)
* AI Principles for People and Planet (DeepMind, 2021)
* AI Ethics Guidelines for China (Chinese Academy of Sciences, 2022)
